{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的模块\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "#获取网页内容\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "#转换成beautifulsoup对象\n",
    "bsObj = BeautifulSoup(html.read(),\"html5lib\")\n",
    "print(bsObj.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#异常处理\n",
    "try:\n",
    "   html = urlopen(\"http://www.xxxxx.html\")\n",
    "#捕获http异常\n",
    "except :\n",
    "    print('error')\n",
    "else:\n",
    "    #程序继续\\\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#完整代码\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bsObj = BeautifulSoup(html.read(),\"html5lib\")\n",
    "        title = bsObj.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "    print(\"Title could not be found\")\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_all\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "url='http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "def getName(url):\n",
    "    try:\n",
    "        html=urlopen(url)\n",
    "    except:\n",
    "        return None\n",
    "    try:\n",
    "        bsobj=BeautifulSoup(html,'html5lib')\n",
    "        names=bsobj.findAll('span',{'class':'green'})\n",
    "    except:\n",
    "        return None\n",
    "    for name in names:\n",
    "        print(name.get_text())\n",
    "        \n",
    "getName(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findAll(tag, attributes, recursive, text, limit, keywords)\n",
    "#find(tag, attributes, recursive, text, keywords)\n",
    "#tag是标签列表,attributes是属性字典,text=''按文本查找\n",
    "#find为limit=1的findAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#其他beautifulsoup对象\n",
    "#使用BeautifulSoup()创建的对象bsobj\n",
    "#使用findAll()或直接调用子标签得到的tag对象:bsobj.div.h1\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "bsObj = BeautifulSoup(html,'html5lib')\n",
    "#查找子标签\n",
    "for child in bsObj.find(\"table\",{\"id\":\"giftList\"}).children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#父标签.兄弟标签,下一个,下所有..\n",
    "#next_siblings 一样，如果你很容易找到一组兄弟标签中的最后一个标签，那么\n",
    "# previous_siblings 函数也会很有用。\n",
    "# 当然，还有 next_sibling 和 previous_sibling 函数，与 next_siblings 和 previous_siblings\n",
    "# 的作用类似，只是它们返回的是单个标签，而不是一组标签。\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "bsObj = BeautifulSoup(html,'html5lib')\n",
    "print(bsObj.find(\"img\",{\"src\":\"../img/gifts/img1.jpg\"\n",
    "}).parent.previous_sibling.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda,attrs\n",
    "bsObj.findAll(lambda tr:len(tr.attrs)==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取链接\n",
    "html=urlopen('http://en.wikipedia.org/wiki/Kevin_Bacon')\n",
    "bsObj=BeautifulSoup(html,'html5lib')\n",
    "for link in bsObj.findAll(\"a\"):\n",
    "    if 'href' in link.attrs:\n",
    "        print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用共同点获取链接:\n",
    "from urllib.request import urlopen \n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "html = urlopen(\"http://en.wikipedia.org/wiki/Kevin_Bacon\")\n",
    "bsObj = BeautifulSoup(html,'html5lib')\n",
    "for link in bsObj.find(\"div\", {\"id\":\"bodyContent\"}).findAll(\"a\",\n",
    "href=re.compile(\"^(/wiki/)((?!:).)*$\")):\n",
    "    if 'href' in link.attrs:\n",
    "        print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取页面的去重\n",
    "from urllib.request import urlopen \n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "pages = set()\n",
    "def getLinks(pageUrl):\n",
    "    global pages\n",
    "    html = urlopen(\"http://en.wikipedia.org\"+pageUrl)\n",
    "    bsObj = BeautifulSoup(html,'html5lib')\n",
    "    for link in bsObj.findAll(\"a\", href=re.compile(\"^(/wiki/)\")):\n",
    "        if 'href' in link.attrs:\n",
    "            if link.attrs['href'] not in pages:\n",
    "            # 我们遇到了新页面\n",
    "                newPage = link.attrs['href'] \n",
    "                print(newPage) \n",
    "                pages.add(newPage) \n",
    "                getLinks(newPage)\n",
    "getLinks(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取ajax\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
